{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd=spark.sparkContext.parallelize([1,2,3,4,5])\n\nrddCollect = rdd.collect()\nprint(\"Number of Partitions: \"+str(rdd.getNumPartitions()))\nprint(\"Action: First element: \"+str(rdd.first()))\nprint(rddCollect)\n\nemptyRDD = spark.sparkContext.emptyRDD()\nemptyRDD2 = rdd=spark.sparkContext.parallelize([])\n\nprint(\"\"+str(emptyRDD2.isEmpty()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2a75023a-7a79-4338-8ff5-909fb9514f44","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Number of Partitions: 8\nAction: First element: 1\n[1, 2, 3, 4, 5]\nTrue\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a70dd88-be9e-4d8e-b3f1-9560c9b7f7cb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-parallelize.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
