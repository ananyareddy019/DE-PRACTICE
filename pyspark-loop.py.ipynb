{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ndata = [('James','Smith','M',30),\n  ('Anna','Rose','F',41),\n  ('Robert','Williams','M',62), \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()\n\nfrom pyspark.sql.functions import concat_ws,col,lit\ndf.select(concat_ws(\",\",df.firstname,df.lastname).alias(\"name\"), \\\n          df.gender,lit(df.salary*2).alias(\"new_salary\")).show()\n\nprint(df.collect())\nrdd=df.rdd.map(lambda x: \n    (x[0]+\",\"+x[1],x[2],x[3]*2)\n    )  \ndf2=rdd.toDF([\"name\",\"gender\",\"new_salary\"]   )\ndf2.show()\n\n\n#Referring Column Names\nrdd2=df.rdd.map(lambda x: \n    (x[\"firstname\"]+\",\"+x[\"lastname\"],x[\"gender\"],x[\"salary\"]*2)\n    ) \n\n\n#Referring Column Names\nrdd2=df.rdd.map(lambda x: \n    (x.firstname+\",\"+x.lastname,x.gender,x.salary*2)\n    ) \n\n\ndef func1(x):\n    firstName=x.firstname\n    lastName=x.lastName\n    name=firstName+\",\"+lastName\n    gender=x.gender.lower()\n    salary=x.salary*2\n    return (name,gender,salary)\n\nrdd2=df.rdd.map(lambda x: func1(x))\n\n#Foeeach example\ndef f(x): print(x)\ndf.rdd.foreach(f)\n\ndf.rdd.foreach(lambda x: \n    print(\"Data ==>\"+x[\"firstname\"]+\",\"+x[\"lastname\"]+\",\"+x[\"gender\"]+\",\"+str(x[\"salary\"]*2))\n    ) \n    \n#Iterate collected data\ndataCollect = df.collect()\nfor row in dataCollect:\n    print(row['firstname'] + \",\" +row['lastname'])\n    \n#Convert to Pandas and Iterate\n\ndataCollect=df.rdd.toLocalIterator()\nfor row in dataCollect:\n    print(row['firstname'] + \",\" +row['lastname'])\n\nimport pandas as pd\npandasDF = df.toPandas()\nfor index, row in pandasDF.iterrows():\n    print(row['firstname'], row['gender'])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e15385a5-b91f-4685-acb4-a6d14a6d95d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|    30|\n|     Anna|    Rose|     F|    41|\n|   Robert|Williams|     M|    62|\n+---------+--------+------+------+\n\n+---------------+------+----------+\n|           name|gender|new_salary|\n+---------------+------+----------+\n|    James,Smith|     M|        60|\n|      Anna,Rose|     F|        82|\n|Robert,Williams|     M|       124|\n+---------------+------+----------+\n\n[Row(firstname='James', lastname='Smith', gender='M', salary=30), Row(firstname='Anna', lastname='Rose', gender='F', salary=41), Row(firstname='Robert', lastname='Williams', gender='M', salary=62)]\n+---------------+------+----------+\n|           name|gender|new_salary|\n+---------------+------+----------+\n|    James,Smith|     M|        60|\n|      Anna,Rose|     F|        82|\n|Robert,Williams|     M|       124|\n+---------------+------+----------+\n\nJames,Smith\nAnna,Rose\nRobert,Williams\nJames,Smith\nAnna,Rose\nRobert,Williams\n"]},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/plain":[],"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}},{"output_type":"stream","output_type":"stream","name":"stdout","text":["James M\nAnna F\nRobert M\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f36daebe-f43f-4192-843c-eeef8d3c8730","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-loop.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
