{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n         .appName('SparkByExamples.com') \\\n         .getOrCreate()\n\ndata = [(\"James\", \"Sales\", 3000),\n    (\"Michael\", \"Sales\", 4600),\n    (\"Robert\", \"Sales\", 4100),\n    (\"Maria\", \"Finance\", 3000),\n    (\"James\", \"Sales\", 3000),\n    (\"Scott\", \"Finance\", 3300),\n    (\"Jen\", \"Finance\", 3900),\n    (\"Jeff\", \"Marketing\", 3000),\n    (\"Kumar\", \"Marketing\", 2000),\n    (\"Saif\", \"Sales\", 4100)\n  ]\ncolumns = [\"Name\",\"Dept\",\"Salary\"]\ndf = spark.createDataFrame(data=data,schema=columns)\ndf.distinct().show()\nprint(\"Distinct Count: \" + str(df.distinct().count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"59d06de8-b7f9-499c-9418-057445730847","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+---------+------+\n|   Name|     Dept|Salary|\n+-------+---------+------+\n|  James|    Sales|  3000|\n|Michael|    Sales|  4600|\n| Robert|    Sales|  4100|\n|  Maria|  Finance|  3000|\n|  Scott|  Finance|  3300|\n|    Jen|  Finance|  3900|\n|   Jeff|Marketing|  3000|\n|  Kumar|Marketing|  2000|\n|   Saif|    Sales|  4100|\n+-------+---------+------+\n\nDistinct Count: 9\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import countDistinct\ndf2=df.select(countDistinct(\"Dept\",\"Salary\"))\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"54b9cce3-9610-46f4-b09d-090e8281e2ad","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------------------------+\n|count(DISTINCT Dept, Salary)|\n+----------------------------+\n|                           8|\n+----------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import countDistinct\ndf2=df.select(countDistinct(\"Dept\",\"Salary\"))\ndf2.show()\n\nprint(\"Distinct Count of Department &amp; Salary: \"+ str(df2.collect()[0][0]))\n\ndf.createOrReplaceTempView(\"PERSON\")\nspark.sql(\"select distinct(count(*)) from PERSON\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"567f55aa-c26a-42eb-910a-95d036efd195","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------------------------+\n|count(DISTINCT Dept, Salary)|\n+----------------------------+\n|                           8|\n+----------------------------+\n\nDistinct Count of Department &amp; Salary: 8\n+--------+\n|count(1)|\n+--------+\n|      10|\n+--------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f4021426-d3f2-4613-88cf-c088136f2fce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Untitled Notebook 2023-06-12 23:46:03","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
